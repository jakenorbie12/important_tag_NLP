{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary feature gen and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import random\n",
    "import torch\n",
    "#import nltk\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFirstCap(x):\n",
    "    if x[0].isupper():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def Length(x):\n",
    "    return len(x)\n",
    "\n",
    "def endY(x):\n",
    "    if x[-1] == 'y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endan(x):\n",
    "    if x[-2:len(x)] == 'an':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def isNum(x):\n",
    "    if x.isnumeric():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endS(x):\n",
    "    if x[-1] == 's':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def endish(x):\n",
    "    if x[-3:len(x)] == 'ish':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endese(x):\n",
    "    if x[-3:len(x)] == 'ese':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def otherCap(x):\n",
    "    for letter in x:\n",
    "        if letter.isupper():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def propVow(x):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    numVow = 0\n",
    "    for letter in x:\n",
    "        if letter in vowels:\n",
    "            numVow += 1\n",
    "    return numVow / len(x)\n",
    "\n",
    "def frontWord(x, array, df):\n",
    "    if x > 0:\n",
    "        return array.index(df['Word'][x-1])\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def backWord(x, array, df):\n",
    "    if x < len(df.index) - 1:\n",
    "        return array.index(df['Word'][x+1])\n",
    "    else:\n",
    "        return -2\n",
    "\n",
    "def Array2Num(x, array):\n",
    "    return array.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Dataset_08-29-2019.txt'\n",
    "df = pd.read_csv(filename, sep = '\\t', encoding = 'unicode_escape')\n",
    "word_data = df['Word'].values.tolist()\n",
    "#word_vec = [nltk.word_tokenize(title) for title in word_data]\n",
    "size = len(word_data) \n",
    "idx_list = [idx + 1 for idx, val in\n",
    "            enumerate(word_data) if val == '.'] \n",
    "res = [word_data[i: j] for i, j in\n",
    "        zip([0] + idx_list, idx_list + \n",
    "        ([size] if idx_list[-1] != size else []))] \n",
    "model = Word2Vec(res, size=24, window=5, min_count=0, workers=4)\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaken\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "C:\\Users\\jaken\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "function_dict = {'isFirstCap': isFirstCap, 'Length': Length, 'endY': endY, 'otherCap': otherCap, 'endan': endan,\n",
    "                  'isNum': isNum, 'endS': endS, 'endish': endish, 'endese': endese, 'propVow': propVow}\n",
    "for f in function_dict:\n",
    "    df[f] = df['Word'].apply(lambda x: function_dict[f](x))\n",
    "wv = KeyedVectors.load('word2vec.model')\n",
    "\n",
    "\n",
    "\n",
    "#NEED TO FIX: WORD2VEC DOESN'T WORK WHEN SAVING TO CSV AND READING IT AGAIN\n",
    "\n",
    "\n",
    "\n",
    "for i in range(24):\n",
    "    df['WordVector' + str(i)] = df['Word'].apply(lambda x: wv[x][i] if x in wv else 0)\n",
    "#df['WordVector'] = df['Word'].apply(lambda x: wv[x] if x in wv else None)\n",
    "tag_array = df.Tag.unique().tolist()\n",
    "df['TagNum'] = df['Tag'].apply(lambda x: Array2Num(x, tag_array))\n",
    "POS_array = df.POS.unique().tolist()\n",
    "df['POSNum'] = df['POS'].apply(lambda x: Array2Num(x, POS_array))\n",
    "word_array = df.Word.unique().tolist()\n",
    "df['frontWord'] = df['Unnamed: 0'].apply(lambda x: frontWord(x, word_array, df))\n",
    "df['backWord'] = df['Unnamed: 0'].apply(lambda x: backWord(x, word_array, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_group = df.groupby(['Sentence #'])\n",
    "test_sentences = []\n",
    "test_dfs = []\n",
    "train_dfs = []\n",
    "max_sent = int(df['Sentence #'].max())\n",
    "for i in range(round(max_sent / 8)):\n",
    "    found = False\n",
    "    while found == False:\n",
    "        num = random.randint(1, max_sent)\n",
    "        if not num in test_sentences:\n",
    "            test_sentences.append(num)\n",
    "            test_dfs.append(sentences_group.get_group(num))\n",
    "            found = True\n",
    "for i in range(round(max_sent / 8)):\n",
    "    found = False\n",
    "    while found == False:\n",
    "        num = random.randint(1, max_sent)\n",
    "        if not num in test_sentences:\n",
    "            test_sentences.append(num)\n",
    "            test_dfs.append(sentences_group.get_group(num))\n",
    "            found = True\n",
    "            \n",
    "test_df = pd.concat(test_dfs)\n",
    "drop_list = test_df['Unnamed: 0'].tolist()\n",
    "train_df = df.copy().drop(drop_list)\n",
    "feature_list = ['isFirstCap', 'Length', 'endY', 'otherCap', 'endan',\n",
    "                   'isNum', 'endS', 'endish', 'endese', 'propVow', 'POSNum', 'frontWord', 'backWord']\n",
    "vectorlist = []\n",
    "for i in range(24):\n",
    "    vectorlist.append('WordVector' + str(i))\n",
    "feature_list = feature_list + vectorlist\n",
    "data_train = train_df[feature_list].values\n",
    "label_train = train_df['TagNum'].values\n",
    "data_test = test_df[feature_list].values\n",
    "label_test = test_df['TagNum'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>isFirstCap</th>\n",
       "      <th>Length</th>\n",
       "      <th>endY</th>\n",
       "      <th>otherCap</th>\n",
       "      <th>endan</th>\n",
       "      <th>...</th>\n",
       "      <th>WordVector18</th>\n",
       "      <th>WordVector19</th>\n",
       "      <th>WordVector20</th>\n",
       "      <th>WordVector21</th>\n",
       "      <th>WordVector22</th>\n",
       "      <th>WordVector23</th>\n",
       "      <th>TagNum</th>\n",
       "      <th>POSNum</th>\n",
       "      <th>frontWord</th>\n",
       "      <th>backWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>-0.003722</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.443563</td>\n",
       "      <td>0.424729</td>\n",
       "      <td>-0.311578</td>\n",
       "      <td>1.228195</td>\n",
       "      <td>4.411615</td>\n",
       "      <td>1.918454</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302861</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>-0.069573</td>\n",
       "      <td>0.299913</td>\n",
       "      <td>1.010724</td>\n",
       "      <td>0.433820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.744413</td>\n",
       "      <td>0.196432</td>\n",
       "      <td>-0.219188</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>2.496732</td>\n",
       "      <td>1.094427</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.355045</td>\n",
       "      <td>0.427268</td>\n",
       "      <td>-0.343154</td>\n",
       "      <td>1.210463</td>\n",
       "      <td>4.213583</td>\n",
       "      <td>1.856411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.395183</td>\n",
       "      <td>0.381858</td>\n",
       "      <td>-0.342208</td>\n",
       "      <td>1.179778</td>\n",
       "      <td>4.213542</td>\n",
       "      <td>1.832739</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>conflict</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084495</td>\n",
       "      <td>0.041270</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.314747</td>\n",
       "      <td>0.138048</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>joined</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093136</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.087761</td>\n",
       "      <td>0.240624</td>\n",
       "      <td>0.117359</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.395183</td>\n",
       "      <td>0.381858</td>\n",
       "      <td>-0.342208</td>\n",
       "      <td>1.179778</td>\n",
       "      <td>4.213542</td>\n",
       "      <td>1.832739</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2.0</td>\n",
       "      <td>protesters</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179721</td>\n",
       "      <td>0.050877</td>\n",
       "      <td>-0.052295</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.572546</td>\n",
       "      <td>0.251046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>who</td>\n",
       "      <td>WP</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.863417</td>\n",
       "      <td>0.219708</td>\n",
       "      <td>-0.214868</td>\n",
       "      <td>0.754948</td>\n",
       "      <td>2.617098</td>\n",
       "      <td>1.150037</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>carried</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125014</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>-0.016937</td>\n",
       "      <td>0.120047</td>\n",
       "      <td>0.442430</td>\n",
       "      <td>0.189280</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>banners</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.016893</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.031080</td>\n",
       "      <td>0.010590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.273730</td>\n",
       "      <td>0.360607</td>\n",
       "      <td>-0.302958</td>\n",
       "      <td>1.096606</td>\n",
       "      <td>3.858187</td>\n",
       "      <td>1.675937</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>such</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322027</td>\n",
       "      <td>0.105404</td>\n",
       "      <td>-0.078049</td>\n",
       "      <td>0.275408</td>\n",
       "      <td>0.962463</td>\n",
       "      <td>0.436210</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>slogans</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056046</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>0.038152</td>\n",
       "      <td>0.156134</td>\n",
       "      <td>0.070611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.240774</td>\n",
       "      <td>0.323139</td>\n",
       "      <td>-0.260858</td>\n",
       "      <td>1.083029</td>\n",
       "      <td>3.707013</td>\n",
       "      <td>1.597340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"</td>\n",
       "      <td>``</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.137026</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>0.929235</td>\n",
       "      <td>3.322981</td>\n",
       "      <td>1.436312</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bush</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-per</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.395211</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>-0.100022</td>\n",
       "      <td>0.327040</td>\n",
       "      <td>1.241777</td>\n",
       "      <td>0.519599</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Number</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.076632</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>One</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049342</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>-0.028477</td>\n",
       "      <td>0.063925</td>\n",
       "      <td>0.223789</td>\n",
       "      <td>0.100072</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Terrorist</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.002825</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>0.071568</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"</td>\n",
       "      <td>``</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.137026</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>0.929235</td>\n",
       "      <td>3.322981</td>\n",
       "      <td>1.436312</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572507</td>\n",
       "      <td>0.451035</td>\n",
       "      <td>-0.356305</td>\n",
       "      <td>1.323103</td>\n",
       "      <td>4.709394</td>\n",
       "      <td>2.039943</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"</td>\n",
       "      <td>``</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.137026</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>0.929235</td>\n",
       "      <td>3.322981</td>\n",
       "      <td>1.436312</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stop</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.050318</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.395183</td>\n",
       "      <td>0.381858</td>\n",
       "      <td>-0.342208</td>\n",
       "      <td>1.179778</td>\n",
       "      <td>4.213542</td>\n",
       "      <td>1.832739</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bombings</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006185</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.343525</td>\n",
       "      <td>0.372946</td>\n",
       "      <td>-0.312621</td>\n",
       "      <td>1.136952</td>\n",
       "      <td>4.074652</td>\n",
       "      <td>1.743568</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"</td>\n",
       "      <td>``</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.137026</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>0.929235</td>\n",
       "      <td>3.322981</td>\n",
       "      <td>1.436312</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Sentence #        Word  POS    Tag  isFirstCap  Length  endY  \\\n",
       "24          24         2.0    Families  NNS      O           1       8     0   \n",
       "25          25         2.0          of   IN      O           0       2     0   \n",
       "26          26         2.0    soldiers  NNS      O           0       8     0   \n",
       "27          27         2.0      killed  VBN      O           0       6     0   \n",
       "28          28         2.0          in   IN      O           0       2     0   \n",
       "29          29         2.0         the   DT      O           0       3     0   \n",
       "30          30         2.0    conflict   NN      O           0       8     0   \n",
       "31          31         2.0      joined  VBD      O           0       6     0   \n",
       "32          32         2.0         the   DT      O           0       3     0   \n",
       "33          33         2.0  protesters  NNS      O           0      10     0   \n",
       "34          34         2.0         who   WP      O           0       3     0   \n",
       "35          35         2.0     carried  VBD      O           0       7     0   \n",
       "36          36         2.0     banners  NNS      O           0       7     0   \n",
       "37          37         2.0        with   IN      O           0       4     0   \n",
       "38          38         2.0        such   JJ      O           0       4     0   \n",
       "39          39         2.0     slogans  NNS      O           0       7     0   \n",
       "40          40         2.0          as   IN      O           0       2     0   \n",
       "41          41         2.0           \"   ``      O           0       1     0   \n",
       "42          42         2.0        Bush  NNP  B-per           1       4     0   \n",
       "43          43         2.0      Number   NN      O           1       6     0   \n",
       "44          44         2.0         One   CD      O           1       3     0   \n",
       "45          45         2.0   Terrorist   NN      O           1       9     0   \n",
       "46          46         2.0           \"   ``      O           0       1     0   \n",
       "47          47         2.0         and   CC      O           0       3     0   \n",
       "48          48         2.0           \"   ``      O           0       1     0   \n",
       "49          49         2.0        Stop   VB      O           1       4     0   \n",
       "50          50         2.0         the   DT      O           0       3     0   \n",
       "51          51         2.0    Bombings  NNS      O           1       8     0   \n",
       "52          52         2.0           .    .      O           0       1     0   \n",
       "53          53         2.0           \"   ``      O           0       1     0   \n",
       "\n",
       "    otherCap  endan  ...  WordVector18  WordVector19  WordVector20  \\\n",
       "24         1      0  ...      0.010567      0.012247     -0.003722   \n",
       "25         0      0  ...     -1.443563      0.424729     -0.311578   \n",
       "26         0      0  ...     -0.302861      0.094733     -0.069573   \n",
       "27         0      0  ...     -0.744413      0.196432     -0.219188   \n",
       "28         0      0  ...     -1.355045      0.427268     -0.343154   \n",
       "29         0      0  ...     -1.395183      0.381858     -0.342208   \n",
       "30         0      0  ...     -0.084495      0.041270     -0.003541   \n",
       "31         0      0  ...     -0.093136      0.009367     -0.014573   \n",
       "32         0      0  ...     -1.395183      0.381858     -0.342208   \n",
       "33         0      0  ...     -0.179721      0.050877     -0.052295   \n",
       "34         0      0  ...     -0.863417      0.219708     -0.214868   \n",
       "35         0      0  ...     -0.125014      0.052511     -0.016937   \n",
       "36         0      0  ...     -0.013289     -0.001120     -0.016893   \n",
       "37         0      0  ...     -1.273730      0.360607     -0.302958   \n",
       "38         0      0  ...     -0.322027      0.105404     -0.078049   \n",
       "39         0      0  ...     -0.056046      0.005060     -0.007802   \n",
       "40         0      0  ...     -1.240774      0.323139     -0.260858   \n",
       "41         0      0  ...     -1.137026      0.280164     -0.215916   \n",
       "42         1      0  ...     -0.395211      0.088334     -0.100022   \n",
       "43         1      0  ...     -0.011305      0.014408      0.010472   \n",
       "44         1      0  ...     -0.049342      0.011571     -0.028477   \n",
       "45         1      0  ...     -0.009509     -0.002825     -0.001151   \n",
       "46         0      0  ...     -1.137026      0.280164     -0.215916   \n",
       "47         0      0  ...     -1.572507      0.451035     -0.356305   \n",
       "48         0      0  ...     -1.137026      0.280164     -0.215916   \n",
       "49         1      0  ...     -0.016632      0.014287      0.009276   \n",
       "50         0      0  ...     -1.395183      0.381858     -0.342208   \n",
       "51         1      0  ...     -0.006185      0.000112     -0.009302   \n",
       "52         0      0  ...     -1.343525      0.372946     -0.312621   \n",
       "53         0      0  ...     -1.137026      0.280164     -0.215916   \n",
       "\n",
       "    WordVector21  WordVector22  WordVector23  TagNum  POSNum  frontWord  \\\n",
       "24      0.010851      0.004688      0.011165       0       0         21   \n",
       "25      1.228195      4.411615      1.918454       0       1         22   \n",
       "26      0.299913      1.010724      0.433820       0       0          1   \n",
       "27      0.726316      2.496732      1.094427       0       3         23   \n",
       "28      1.210463      4.213583      1.856411       0       1         24   \n",
       "29      1.179778      4.213542      1.832739       0       7         11   \n",
       "30      0.085129      0.314747      0.138048       0       8          9   \n",
       "31      0.087761      0.240624      0.117359       0      12         25   \n",
       "32      1.179778      4.213542      1.832739       0       7         26   \n",
       "33      0.173662      0.572546      0.251046       0       0          9   \n",
       "34      0.754948      2.617098      1.150037       0      13         27   \n",
       "35      0.120047      0.442430      0.189280       0      12         28   \n",
       "36      0.018015      0.031080      0.010590       0       0         29   \n",
       "37      1.096606      3.858187      1.675937       0       1         30   \n",
       "38      0.275408      0.962463      0.436210       0      10         31   \n",
       "39      0.038152      0.156134      0.070611       0       0         32   \n",
       "40      1.083029      3.707013      1.597340       0       1         33   \n",
       "41      0.929235      3.322981      1.436312       0      14         34   \n",
       "42      0.327040      1.241777      0.519599       3       4         35   \n",
       "43      0.008862      0.076632      0.047500       0       8         36   \n",
       "44      0.063925      0.223789      0.100072       0      15         37   \n",
       "45     -0.005017      0.071568      0.026937       0       8         38   \n",
       "46      0.929235      3.322981      1.436312       0      14         39   \n",
       "47      1.323103      4.709394      2.039943       0       9         35   \n",
       "48      0.929235      3.322981      1.436312       0      14         13   \n",
       "49      0.004404      0.050318      0.015101       0       6         35   \n",
       "50      1.179778      4.213542      1.832739       0       7         40   \n",
       "51      0.023605      0.030309      0.015987       0       0          9   \n",
       "52      1.136952      4.074652      1.743568       0      11         41   \n",
       "53      0.929235      3.322981      1.436312       0      14         21   \n",
       "\n",
       "    backWord  \n",
       "24         1  \n",
       "25        23  \n",
       "26        24  \n",
       "27        11  \n",
       "28         9  \n",
       "29        25  \n",
       "30        26  \n",
       "31         9  \n",
       "32        27  \n",
       "33        28  \n",
       "34        29  \n",
       "35        30  \n",
       "36        31  \n",
       "37        32  \n",
       "38        33  \n",
       "39        34  \n",
       "40        35  \n",
       "41        36  \n",
       "42        37  \n",
       "43        38  \n",
       "44        39  \n",
       "45        35  \n",
       "46        13  \n",
       "47        35  \n",
       "48        40  \n",
       "49         9  \n",
       "50        41  \n",
       "51        21  \n",
       "52        35  \n",
       "53        42  \n",
       "\n",
       "[30 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_group.get_group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_list)\n",
    "input_size = 37\n",
    "hidden_sizes = [30, 23]\n",
    "#length of num_classes\n",
    "output_size = 17\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "    ('softmax', nn.Softmax(dim=1))\n",
    "]))\n",
    "\n",
    "'''\n",
    "multiplier_list = []\n",
    "for num in range(output_size):\n",
    "    multiplier_list.append(np.count_nonzero(label_train == num))\n",
    "'''\n",
    "weights = torch.tensor([1,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5])\n",
    "\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.30704628084407\n",
      "Training loss: 1.3034968411039916\n",
      "Training loss: 1.2936676207244115\n",
      "Training loss: 1.2925609007643075\n",
      "Training loss: 1.2936651453426053\n",
      "Training loss: 1.292360126636491\n",
      "Training loss: 1.2879250919927714\n",
      "Training loss: 1.284025960593684\n",
      "Training loss: 1.2837773796578509\n",
      "Training loss: 1.2855848310766373\n",
      "Accuracy Score: 0.8806800992315604\n",
      "[[13878    66    87     0     0    47     0    24     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   35   397     5     0     0    70     0     4     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   46    51   148     0     0    28     0     2     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   65    60     6     0     0   136     0     3     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   46    13     3     0     0    15     0     1     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   39   156     8     0     0    98     0     5     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [  111    40     2     0     0    71     0     2     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [  173    35     3     0     0    46     0    34     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     7     0     0     0     6     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    3     0     0     0     0     7     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [  155    32    11     0     0   110     0     2     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    3     2     0     0     0     3     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   92     4     0     0     0     2     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    3     7     0     0     0     2     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     4     0     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    4     1     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    2     0     0     0     0     1     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "x_factor = np.count_nonzero(label_train == 0)\n",
    "for i in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for idx, word in enumerate(data_train):\n",
    "        label = label_train[idx]\n",
    "        optimizer.zero_grad()\n",
    "        word = np.array([word])\n",
    "        word = torch.from_numpy(word)\n",
    "        output = model(word.float())\n",
    "        target_list = []\n",
    "        for i in range(output_size):\n",
    "            if i == label:\n",
    "                if i == 0:\n",
    "                    target_list.append(float(1))\n",
    "                else:\n",
    "                    target_list.append(float(3))\n",
    "            else:\n",
    "                target_list.append(float(0))\n",
    "        target = torch.tensor([target_list])\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(data_train)}\")\n",
    "        \n",
    "correct = 0\n",
    "total = 0\n",
    "total_list = []\n",
    "for idx, guess in enumerate(data_test):\n",
    "    word = np.array([guess])\n",
    "    word = torch.from_numpy(word)\n",
    "    output = model(word.float())\n",
    "    guess_list = output[0].detach().numpy().tolist()\n",
    "    total_list.append(guess_list)\n",
    "\n",
    "\n",
    "classed_data = [np.argmax(line) for line in total_list]\n",
    "accuracy = accuracy_score(classed_data, label_test)\n",
    "cm = confusion_matrix(label_test, classed_data)\n",
    "print('Accuracy Score: ' + str(accuracy))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#TO FIX!!!! MODEL ONLY KICKS OUT 0'S\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm and normal project stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9543776850003025\n",
      "[[14042    10     5    18     1     3     6     4     0     0     9     0\n",
      "      4     0     0     0     0]\n",
      " [   13   429    17     6     3    34     2     2     0     0     4     0\n",
      "      0     0     1     0     0]\n",
      " [    9    36   215     2     1     7     3     0     0     0     2     0\n",
      "      0     0     0     0     0]\n",
      " [    6    15     2   205     0    11     4     1     0     0    26     0\n",
      "      0     0     0     0     0]\n",
      " [    6     7     1     1    42     2    11     0     0     0     8     0\n",
      "      0     0     0     0     0]\n",
      " [   19    56     9    13     1   182    13     1     0     0    10     0\n",
      "      0     0     2     0     0]\n",
      " [   35     8     0    14     6     8   125     0     0     1    28     0\n",
      "      0     0     0     1     0]\n",
      " [   54     4     0     0     0     1     0   226     0     0     1     0\n",
      "      5     0     0     0     0]\n",
      " [    2     4     0     2     0     5     0     0     1     0     1     0\n",
      "      0     0     0     0     0]\n",
      " [    0     0     0     1     1     1     3     0     0     0     3     0\n",
      "      1     0     0     0     0]\n",
      " [    9     0     0    24     4     1     4     0     0     0   267     0\n",
      "      0     0     0     0     1]\n",
      " [    1     1     0     0     5     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0]\n",
      " [   52     1     0     1     0     0     0    13     0     0     1     0\n",
      "     30     0     0     0     0]\n",
      " [    5     2     0     0     0     1     1     0     0     0     1     0\n",
      "      0     2     0     0     0]\n",
      " [    2     2     0     0     0     1     0     0     0     0     0     0\n",
      "      0     0     2     0     0]\n",
      " [    2     0     0     0     0     0     0     0     0     0     1     0\n",
      "      0     0     0     2     0]\n",
      " [    0     0     0     1     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     2]]\n"
     ]
    }
   ],
   "source": [
    "d_train = lgb.Dataset(data_train, label=label_train)\n",
    "params = {}\n",
    "params['objective'] = 'multiclass'\n",
    "params['num_classes'] = 17\n",
    "params['learning_rate'] = 0.03\n",
    "params['colsample_bytree'] = 0.7\n",
    "params['max_depth'] = 20\n",
    "params['min_split_gain'] = 0.3\n",
    "params['n_estimators'] = 400\n",
    "params['num_leaves'] = 100\n",
    "params['reg_alpha'] = 1.1\n",
    "params['reg_lambda'] = 1.3\n",
    "params['subsample'] = 0.9\n",
    "params['subsample_freq'] = 20\n",
    "mod = lgb.train(params, d_train, 100)\n",
    "prediction_data = mod.predict(data_test)\n",
    "classed_data = [np.argmax(line) for line in prediction_data]\n",
    "accuracy = accuracy_score(classed_data, label_test)\n",
    "cm = confusion_matrix(label_test, classed_data)\n",
    "print(accuracy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
