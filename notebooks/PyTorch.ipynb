{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import torch\n",
    "#import nltk\n",
    "from torch import nn, optim\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFirstCap(x):\n",
    "    if x[0].isupper():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def Length(x):\n",
    "    return len(x)\n",
    "\n",
    "def endY(x):\n",
    "    if x[-1] == 'y':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endan(x):\n",
    "    if x[-2:len(x)] == 'an':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def isNum(x):\n",
    "    if x.isnumeric():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endS(x):\n",
    "    if x[-1] == 's':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def endish(x):\n",
    "    if x[-3:len(x)] == 'ish':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def endese(x):\n",
    "    if x[-3:len(x)] == 'ese':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def otherCap(x):\n",
    "    for letter in x:\n",
    "        if letter.isupper():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def propVow(x):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    numVow = 0\n",
    "    for letter in x:\n",
    "        if letter in vowels:\n",
    "            numVow += 1\n",
    "    return numVow / len(x)\n",
    "\n",
    "def frontWord(x, array, df):\n",
    "    if x > 0:\n",
    "        return array.index(df['Word'][x-1])\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def backWord(x, array, df):\n",
    "    if x < len(df.index) - 1:\n",
    "        return array.index(df['Word'][x+1])\n",
    "    else:\n",
    "        return -2\n",
    "\n",
    "def Array2Num(x, array):\n",
    "    return array.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Dataset_08-29-2019.txt'\n",
    "df = pd.read_csv(filename, sep = '\\t', encoding = 'unicode_escape')\n",
    "word_data = df['Word'].values.tolist()\n",
    "#word_vec = [nltk.word_tokenize(title) for title in word_data]\n",
    "size = len(word_data) \n",
    "idx_list = [idx + 1 for idx, val in\n",
    "            enumerate(word_data) if val == '.'] \n",
    "res = [word_data[i: j] for i, j in\n",
    "        zip([0] + idx_list, idx_list + \n",
    "        ([size] if idx_list[-1] != size else []))] \n",
    "model = Word2Vec(res, size=24, window=5, min_count=0, workers=4)\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaken\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "C:\\Users\\jaken\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "function_dict = {'isFirstCap': isFirstCap, 'Length': Length, 'endY': endY, 'otherCap': otherCap, 'endan': endan,\n",
    "                  'isNum': isNum, 'endS': endS, 'endish': endish, 'endese': endese, 'propVow': propVow}\n",
    "for f in function_dict:\n",
    "    df[f] = df['Word'].apply(lambda x: function_dict[f](x))\n",
    "wv = KeyedVectors.load('word2vec.model')\n",
    "\n",
    "\n",
    "\n",
    "#NEED TO FIX: WORD2VEC DOESN'T WORK WHEN SAVING TO CSV AND READING IT AGAIN\n",
    "\n",
    "\n",
    "\n",
    "for i in range(24):\n",
    "    df['WordVector' + str(i)] = df['Word'].apply(lambda x: wv[x][i] if x in wv else 0)\n",
    "#df['WordVector'] = df['Word'].apply(lambda x: wv[x] if x in wv else None)\n",
    "tag_array = df.Tag.unique().tolist()\n",
    "df['TagNum'] = df['Tag'].apply(lambda x: Array2Num(x, tag_array))\n",
    "POS_array = df.POS.unique().tolist()\n",
    "df['POSNum'] = df['POS'].apply(lambda x: Array2Num(x, POS_array))\n",
    "word_array = df.Word.unique().tolist()\n",
    "df['frontWord'] = df['Unnamed: 0'].apply(lambda x: frontWord(x, word_array, df))\n",
    "df['backWord'] = df['Unnamed: 0'].apply(lambda x: backWord(x, word_array, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_group = df.groupby(['Sentence #'])\n",
    "test_sentences = []\n",
    "test_dfs = []\n",
    "train_dfs = []\n",
    "max_sent = int(df['Sentence #'].max())\n",
    "for i in range(round(max_sent / 4)):\n",
    "    found = False\n",
    "    while found == False:\n",
    "        num = random.randint(1, 2999)\n",
    "        if not num in test_sentences:\n",
    "            test_sentences.append(num)\n",
    "            test_dfs.append(sentences_group.get_group(num))\n",
    "            found = True\n",
    "            \n",
    "test_df = pd.concat(test_dfs)\n",
    "drop_list = test_df['Unnamed: 0'].tolist()\n",
    "train_df = df.copy().drop(drop_list)\n",
    "feature_list = ['isFirstCap', 'Length', 'endY', 'otherCap', 'endan',\n",
    "                   'isNum', 'endS', 'endish', 'endese', 'propVow', 'POSNum', 'frontWord', 'backWord']\n",
    "vectorlist = []\n",
    "for i in range(24):\n",
    "    vectorlist.append('WordVector' + str(i))\n",
    "feature_list = feature_list + vectorlist\n",
    "data_train = train_df[feature_list].values\n",
    "label_train = train_df['TagNum'].values\n",
    "data_test = test_df[feature_list].values\n",
    "label_test = test_df['TagNum'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feature_list)\n",
    "input_size = 37\n",
    "hidden_sizes = [28, 20]\n",
    "#length of num_classes\n",
    "output_size = 17\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "    ('softmax', nn.Softmax())\n",
    "]))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaken\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:445: UserWarning: Using a target size (torch.Size([17])) that is different to the input size (torch.Size([1, 17])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01775388409583978\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for idx, word in enumerate(data_train):\n",
    "        label = label_train[idx]\n",
    "        optimizer.zero_grad()\n",
    "        word = np.array([word])\n",
    "        word = torch.from_numpy(word)\n",
    "        output = model(word.float())\n",
    "        target_list = []\n",
    "        for i in range(output_size):\n",
    "            if i == label:\n",
    "                target_list.append(float(1))\n",
    "            else:\n",
    "                target_list.append(float(0))\n",
    "        target = torch.tensor(target_list)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(data_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for idx, guess in enumerate(data_test):\n",
    "    label = label_test[idx]\n",
    "    word = np.array([guess])\n",
    "    word = torch.from_numpy(word)\n",
    "    output = model(word.float())\n",
    "    guess_list = output[0].detach().numpy().tolist()\n",
    "    y_pred = np.argmax(guess_list)\n",
    "    if label == y_pred:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#TO FIX!!!! MODEL ONLY KICKS OUT 0'S\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy Score: ' + str(correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8395, -2.0503,  1.0265, -0.9692,  0.5900],\n",
      "        [-0.2555, -0.3642, -0.6948, -0.4677,  0.1303],\n",
      "        [ 0.1413, -2.5228,  0.3395,  1.2348,  1.2189]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
