{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import wheel\n",
    "import setuptools\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('Dataset_08-29-2019.txt', sep='\\t', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Functions shell\n",
    "\n",
    "def otherCap(x):\n",
    "    for letter in x:\n",
    "        if letter.isupper():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def propVow(x):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    numVow = 0\n",
    "    for letter in x:\n",
    "        if letter in vowels:\n",
    "            numVow += 1\n",
    "    return numVow / len(x)\n",
    "\n",
    "word_array = df.Word.unique().tolist()\n",
    "\n",
    "def frontWord(x):\n",
    "    if x > 0:\n",
    "        return word_array.index(df['Word'][x-1])\n",
    "    else:\n",
    "        return\n",
    "def backWord(x):\n",
    "    if x < len(df.index) - 1:\n",
    "        return word_array.index(df['Word'][x+1])\n",
    "    else:\n",
    "        return\n",
    "\n",
    "array = df.Tag.unique().tolist()\n",
    "def Tag2Num(x):\n",
    "    return array.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isFirstCap'] = df['Word'].apply(lambda x: 1 if x[0].isupper() else 0)\n",
    "\n",
    "df['Length'] = df['Word'].apply(lambda x: len(x))\n",
    "\n",
    "df['endY'] = df['Word'].apply(lambda x: 1 if x[-1] == 'y' else 0)\n",
    "\n",
    "df['isNNP'] = df['POS'].apply(lambda x: 1 if x == 'NNP' else 0)\n",
    "\n",
    "df['isJJ'] = df['POS'].apply(lambda x: 1 if x == 'JJ' else 0)\n",
    "\n",
    "df['isCD'] = df['POS'].apply(lambda x: 1 if x == 'CD' else 0)\n",
    "\n",
    "df['otherCap'] = df['Word'].apply(lambda x: otherCap(x))\n",
    "\n",
    "df['endan'] = df['Word'].apply(lambda x: 1 if x[-2:len(x)] == 'an' else 0)\n",
    "\n",
    "df['isNum'] = df['Word'].apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "\n",
    "df['endS'] = df['Word'].apply(lambda x: 1 if x[-1] == 's' else 0)\n",
    "\n",
    "df['endish'] = df['Word'].apply(lambda x: 1 if x[-3:len(x)] == 'ish' else 0)\n",
    "\n",
    "df['endese'] = df['Word'].apply(lambda x: 1 if x[-3:len(x)] == 'ese' else 0)\n",
    "\n",
    "df['propVow'] = df['Word'].apply(lambda x: propVow(x))\n",
    "\n",
    "df['TagNum'] = df['Tag'].apply(lambda x: Tag2Num(x))\n",
    "\n",
    "df['frontWord'] = df['Unnamed: 0'].apply(lambda x: frontWord(x))\n",
    "\n",
    "df['backWord'] = df['Unnamed: 0'].apply(lambda x: backWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_group = df.groupby(['Sentence #'])\n",
    "test_sentences = []\n",
    "test_dfs = []\n",
    "train_dfs = []\n",
    "for i in range(750):\n",
    "    found = False\n",
    "    while found == False:\n",
    "        num = random.randint(1, 2999)\n",
    "        if not num in test_sentences:\n",
    "            test_sentences.append(num)\n",
    "            test_dfs.append(sentences_group.get_group(num))\n",
    "            found = True\n",
    "            \n",
    "test_df = pd.concat(test_dfs)\n",
    "drop_list = test_df['Unnamed: 0'].tolist()\n",
    "train_df = df.copy().drop(drop_list)\n",
    "\n",
    "data_train = train_df[['isFirstCap', 'Length', 'endY', 'isNNP', 'isJJ', 'isCD', 'otherCap', 'endan',\n",
    "           'isNum', 'endS', 'endish', 'endese', 'propVow', 'frontWord', 'backWord']].values\n",
    "valid_train = train_df['TagNum'].values\n",
    "data_test = test_df[['isFirstCap', 'Length', 'endY', 'isNNP', 'isJJ', 'isCD', 'otherCap', 'endan',\n",
    "           'isNum', 'endS', 'endish', 'endese', 'propVow', 'frontWord', 'backWord']].values\n",
    "valid_test = test_df['TagNum'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(data_train, label=valid_train)\n",
    "parameters = {}\n",
    "parameters['objective'] = 'multiclass'\n",
    "parameters['num_class'] = 17\n",
    "parameters['learning_rate'] = 0.03\n",
    "d = lgb.train(parameters, train_data, 100)\n",
    "#Save the model\n",
    "d.save_model('model.txt')\n",
    "y_pred = d.predict(data_test)\n",
    "y_hat = [np.argmax(line) for line in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9362660414610069\n",
      "[[13701     8    19     8     0     9     5     3     0     0    13     0\n",
      "      2     1     1     0     0]\n",
      " [   26   373     6    17     0    55    11     6     0     0    22     0\n",
      "      0     0     1     2     0]\n",
      " [   21    59   196     4     1     7     2     0     0     0     3     1\n",
      "      0     1     0     0     0]\n",
      " [   10    35     2   175     1    15     7     6     0     2    26     0\n",
      "      0     0     0     0     1]\n",
      " [   10     9     2     5    55     3     4     3     0     0    14     3\n",
      "      0     0     0     0     0]\n",
      " [   19    67     6    34     4   127     9     9     3     0    21     0\n",
      "      0     0     1     0     0]\n",
      " [   33    12     1    11     9     8    78     7     0     0    53     1\n",
      "      0     0     0     1     0]\n",
      " [   70    16     2     1     0     5     1   190     0     0     3     0\n",
      "      3     0     0     0     0]\n",
      " [    1     6     0     2     1     2     0     0     0     0     2     0\n",
      "      0     0     0     0     0]\n",
      " [    1     0     0     1     0     0     2     0     0     0     4     0\n",
      "      0     0     0     0     0]\n",
      " [   10     4     1    14     3     0    24     3     0     0   251     0\n",
      "      0     0     0     0     0]\n",
      " [    0     1     1     0     3     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0]\n",
      " [   40     2     0     2     0     0     0     8     0     0     0     0\n",
      "     26     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     1     0     0     0     0\n",
      "      0     1     0     0     0]\n",
      " [    0     1     0     1     0     2     0     0     0     0     3     0\n",
      "      0     0     0     0     0]\n",
      " [    0     0     0     0     1     0     0     0     0     0     3     0\n",
      "      0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid_test, y_hat)\n",
    "accuracy = accuracy_score(y_hat, valid_test)\n",
    "print(accuracy)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
