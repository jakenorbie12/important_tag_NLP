{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import wheel\n",
    "import setuptools\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('Dataset_08-29-2019.txt', sep='\\t', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Functions shell\n",
    "\n",
    "def otherCap(x):\n",
    "    for letter in x:\n",
    "        if letter.isupper():\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def propVow(x):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    numVow = 0\n",
    "    for letter in x:\n",
    "        if letter in vowels:\n",
    "            numVow += 1\n",
    "    return numVow / len(x)\n",
    "\n",
    "word_array = df.Word.unique().tolist()\n",
    "\n",
    "def frontWord(x):\n",
    "    if x > 0:\n",
    "        return word_array.index(df['Word'][x-1])\n",
    "    else:\n",
    "        return\n",
    "def backWord(x):\n",
    "    if x < len(df.index) - 1:\n",
    "        return word_array.index(df['Word'][x+1])\n",
    "    else:\n",
    "        return\n",
    "\n",
    "array = df.Tag.unique().tolist()\n",
    "def Tag2Num(x):\n",
    "    return array.index(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isFirstCap'] = df['Word'].apply(lambda x: 1 if x[0].isupper() else 0)\n",
    "\n",
    "df['Length'] = df['Word'].apply(lambda x: len(x))\n",
    "\n",
    "df['endY'] = df['Word'].apply(lambda x: 1 if x[-1] == 'y' else 0)\n",
    "\n",
    "df['isNNP'] = df['POS'].apply(lambda x: 1 if x == 'NNP' else 0)\n",
    "\n",
    "df['isJJ'] = df['POS'].apply(lambda x: 1 if x == 'JJ' else 0)\n",
    "\n",
    "df['isCD'] = df['POS'].apply(lambda x: 1 if x == 'CD' else 0)\n",
    "\n",
    "df['otherCap'] = df['Word'].apply(lambda x: otherCap(x))\n",
    "\n",
    "df['endan'] = df['Word'].apply(lambda x: 1 if x[-2:len(x)] == 'an' else 0)\n",
    "\n",
    "df['isNum'] = df['Word'].apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "\n",
    "df['endS'] = df['Word'].apply(lambda x: 1 if x[-1] == 's' else 0)\n",
    "\n",
    "df['endish'] = df['Word'].apply(lambda x: 1 if x[-3:len(x)] == 'ish' else 0)\n",
    "\n",
    "df['endese'] = df['Word'].apply(lambda x: 1 if x[-3:len(x)] == 'ese' else 0)\n",
    "\n",
    "df['propVow'] = df['Word'].apply(lambda x: propVow(x))\n",
    "\n",
    "df['TagNum'] = df['Tag'].apply(lambda x: Tag2Num(x))\n",
    "\n",
    "df['frontWord'] = df['Unnamed: 0'].apply(lambda x: frontWord(x))\n",
    "\n",
    "df['backWord'] = df['Unnamed: 0'].apply(lambda x: backWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_group = df.groupby(['Sentence #'])\n",
    "test_sentences = []\n",
    "test_dfs = []\n",
    "train_dfs = []\n",
    "for i in range(750):\n",
    "    found = False\n",
    "    while found == False:\n",
    "        num = random.randint(1, 2999)\n",
    "        if not num in test_sentences:\n",
    "            test_sentences.append(num)\n",
    "            test_dfs.append(sentences_group.get_group(num))\n",
    "            found = True\n",
    "            \n",
    "test_df = pd.concat(test_dfs)\n",
    "drop_list = test_df['Unnamed: 0'].tolist()\n",
    "train_df = df.copy().drop(drop_list)\n",
    "\n",
    "data_train = train_df[['isFirstCap', 'Length', 'endY', 'isNNP', 'isJJ', 'isCD', 'otherCap', 'endan',\n",
    "           'isNum', 'endS', 'endish', 'endese', 'propVow', 'frontWord', 'backWord']].values\n",
    "valid_train = train_df['TagNum'].values\n",
    "data_test = test_df[['isFirstCap', 'Length', 'endY', 'isNNP', 'isJJ', 'isCD', 'otherCap', 'endan',\n",
    "           'isNum', 'endS', 'endish', 'endese', 'propVow', 'frontWord', 'backWord']].values\n",
    "valid_test = test_df['TagNum'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(data_train, label=valid_train)\n",
    "parameters = {}\n",
    "parameters['objective'] = 'multiclass'\n",
    "parameters['num_class'] = 17\n",
    "parameters['learning_rate'] = 0.03\n",
    "d = lgb.train(parameters, train_data, 100)\n",
    "#Save the model\n",
    "d.save_model('model.txt')\n",
    "y_pred = d.predict(data_test)\n",
    "y_hat = [np.argmax(line) for line in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9397362315301013\n",
      "0.9367691031146622\n",
      "[[13914     8    22    12     0    17     4     3     0     0    23     0\n",
      "      4     1     0     0     8]\n",
      " [   14   380    13    20     2    40     8     4     0     0    19     0\n",
      "      0     0     0     1     0]\n",
      " [   18    43   208     4     1     4     1     4     0     0     6     1\n",
      "      0     0     0     0     0]\n",
      " [    8    31     2   178     0    13     5     5     0     0    26     0\n",
      "      0     2     0     1     0]\n",
      " [    9    12     0     1    34     1     9     1     0     0    22     2\n",
      "      0     0     0     0     0]\n",
      " [   25    84     9    27     3   120    16     4     1     0    12     0\n",
      "      0     0     0     0     0]\n",
      " [   28    11     1    15    10     5    83     8     0     1    30     0\n",
      "      0     0     0     0     1]\n",
      " [   55    16     0     4     0     8     0   203     0     0     2     0\n",
      "      1     0     0     0     0]\n",
      " [    2     1     1     0     0     1     2     0     1     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [    3     0     0     0     0     0     1     0     0     0     3     0\n",
      "      0     0     0     0     0]\n",
      " [    7     3     0    13     2     3    17     5     0     1   239     0\n",
      "      0     0     0     0     1]\n",
      " [    0     0     1     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]\n",
      " [   45     2     0     1     0     0     1    10     0     0     0     0\n",
      "     27     0     0     0     0]\n",
      " [    3     3     0     0     0     0     0     0     0     0     0     0\n",
      "      0     1     0     0     0]\n",
      " [    2     3     0     1     0     2     0     2     0     0     1     0\n",
      "      0     0     1     0     0]\n",
      " [    5     0     0     1     0     0     1     0     0     0     4     0\n",
      "      0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     1     0\n",
      "      0     0     0     0     2]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(valid_test, y_hat)\n",
    "accuracy = accuracy_score(y_hat, valid_test)\n",
    "f1 = f1_score(valid_test, y_hat, average = 'weighted')\n",
    "print(accuracy)\n",
    "print(f1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
